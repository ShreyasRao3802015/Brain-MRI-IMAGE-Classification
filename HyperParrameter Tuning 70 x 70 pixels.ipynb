{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "balanced-edgar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-somalia",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "false-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'C:/Users/LightSpeed/Light Speed/Deep Learning/Brain Tumor Classification MRI/Training'\n",
    "categories = ['glioma_tumor','meningioma_tumor','no_tumor','pituitary_tumor']\n",
    "train_images = []\n",
    "train_labels = []\n",
    "for category in categories:\n",
    "    path = os.path.join(datadir,category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        img_array = cv2.resize(img_array,(70,70) )\n",
    "        train_images.append(img_array)\n",
    "        train_labels.append(categories.index(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grand-requirement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2870, 2870)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images),len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "manual-painting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 70, 3), (2870,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "train_images.shape[1:], train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "frank-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agreed-equivalent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-inside",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "colonial-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.normpath('C:/Users/LightSpeed/Light Speed/Deep Learning/Brain Tumor Classification MRI/Testing')\n",
    "categories = ['glioma_tumor','meningioma_tumor','no_tumor','pituitary_tumor']\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for category in categories:\n",
    "    path = os.path.join(datadir,category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        img_array = cv2.resize(img_array,(70,70) )\n",
    "        test_images.append(img_array)\n",
    "        test_labels.append(categories.index(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pending-apple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 394)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images),len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "infectious-tomato",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 70, 3), (394,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "test_images.shape[1:], test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aboriginal-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "charged-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
    "from tensorflow.python.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.python.keras import regularizers\n",
    "\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "engaging-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay) ,input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "model.add(Conv2D(64,(3,3), kernel_regularizer=regularizers.l2(weight_decay) , padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "model.add(Conv2D(128,(3,3), kernel_regularizer=regularizers.l2(weight_decay) , padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "model.add(Conv2D(256,(3,3), kernel_regularizer=regularizers.l2(weight_decay) , padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "model.add(Conv2D(512,(3,3), kernel_regularizer=regularizers.l2(weight_decay) , padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "#6th Convolutional Layer\n",
    "model.add(Conv2D(1024,(3,3), kernel_regularizer=regularizers.l2(weight_decay) , padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confused-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(0.1)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "generic-publicity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 1.5486 - accuracy: 0.3962 - val_loss: 2.3251 - val_accuracy: 0.2056\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 1.3054 - accuracy: 0.4777 - val_loss: 2.8805 - val_accuracy: 0.2665\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 1.2534 - accuracy: 0.4934 - val_loss: 3.6216 - val_accuracy: 0.2614\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 1.2604 - accuracy: 0.4850 - val_loss: 2.3601 - val_accuracy: 0.3096\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 1.2340 - accuracy: 0.5098 - val_loss: 3.6501 - val_accuracy: 0.2107\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 1.1679 - accuracy: 0.5495 - val_loss: 3.0507 - val_accuracy: 0.2919\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 1.1551 - accuracy: 0.5505 - val_loss: 2.4722 - val_accuracy: 0.3122\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 1.1063 - accuracy: 0.5721 - val_loss: 2.7480 - val_accuracy: 0.2970\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 1.0874 - accuracy: 0.5948 - val_loss: 3.9209 - val_accuracy: 0.2970\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 1.0666 - accuracy: 0.6014 - val_loss: 2.3273 - val_accuracy: 0.3173\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 1.0960 - accuracy: 0.5624 - val_loss: 3.7712 - val_accuracy: 0.3350\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 3s 39ms/step - loss: 1.1014 - accuracy: 0.5544 - val_loss: 4.0899 - val_accuracy: 0.2970\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 1.0520 - accuracy: 0.5927 - val_loss: 4.6868 - val_accuracy: 0.3173\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.9873 - accuracy: 0.6028 - val_loss: 4.5794 - val_accuracy: 0.2513\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 1.0340 - accuracy: 0.6310 - val_loss: 3.3188 - val_accuracy: 0.3756\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.9633 - accuracy: 0.6526 - val_loss: 2.8958 - val_accuracy: 0.3579\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.9425 - accuracy: 0.6516 - val_loss: 4.7639 - val_accuracy: 0.2944\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.9637 - accuracy: 0.6564 - val_loss: 3.2669 - val_accuracy: 0.3528\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.9585 - accuracy: 0.6613 - val_loss: 3.8641 - val_accuracy: 0.3426\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.9092 - accuracy: 0.6707 - val_loss: 2.0831 - val_accuracy: 0.4315\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.9198 - accuracy: 0.6784 - val_loss: 1.7671 - val_accuracy: 0.4746\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.8623 - accuracy: 0.7056 - val_loss: 3.0423 - val_accuracy: 0.4543\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.8577 - accuracy: 0.7247 - val_loss: 4.6032 - val_accuracy: 0.3731\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.8346 - accuracy: 0.7512 - val_loss: 2.6030 - val_accuracy: 0.4365\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.7996 - accuracy: 0.7718 - val_loss: 5.6169 - val_accuracy: 0.3299\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.7798 - accuracy: 0.7721 - val_loss: 3.1242 - val_accuracy: 0.4695\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.7955 - accuracy: 0.7805 - val_loss: 3.3830 - val_accuracy: 0.4746\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.7721 - accuracy: 0.7840 - val_loss: 3.6245 - val_accuracy: 0.4772\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.7853 - accuracy: 0.7854 - val_loss: 7.2165 - val_accuracy: 0.3020\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.7418 - accuracy: 0.7927 - val_loss: 4.4153 - val_accuracy: 0.4670\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.6738 - accuracy: 0.8226 - val_loss: 5.6751 - val_accuracy: 0.4340\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.7166 - accuracy: 0.8094 - val_loss: 4.2034 - val_accuracy: 0.4340\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.6995 - accuracy: 0.8258 - val_loss: 2.6273 - val_accuracy: 0.5228\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.7203 - accuracy: 0.8084 - val_loss: 3.9728 - val_accuracy: 0.4619\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 0.6776 - accuracy: 0.8321 - val_loss: 4.3532 - val_accuracy: 0.4924\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.6798 - accuracy: 0.8268 - val_loss: 1.8541 - val_accuracy: 0.5964\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.6627 - accuracy: 0.8394 - val_loss: 1.9787 - val_accuracy: 0.5355\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.6277 - accuracy: 0.8564 - val_loss: 7.5297 - val_accuracy: 0.4315\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.6289 - accuracy: 0.8596 - val_loss: 4.8894 - val_accuracy: 0.5127\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.6587 - accuracy: 0.8429 - val_loss: 4.5406 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.6448 - accuracy: 0.8540 - val_loss: 1.8336 - val_accuracy: 0.6599\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.6084 - accuracy: 0.8662 - val_loss: 4.0852 - val_accuracy: 0.5584\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.6315 - accuracy: 0.8554 - val_loss: 2.1925 - val_accuracy: 0.6193\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.6020 - accuracy: 0.8697 - val_loss: 9.0255 - val_accuracy: 0.3756\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.5974 - accuracy: 0.8679 - val_loss: 6.3383 - val_accuracy: 0.5127\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.6393 - accuracy: 0.8596 - val_loss: 4.2666 - val_accuracy: 0.5635\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.6066 - accuracy: 0.8763 - val_loss: 3.4987 - val_accuracy: 0.6015\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.5597 - accuracy: 0.8899 - val_loss: 3.2881 - val_accuracy: 0.6548\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.5479 - accuracy: 0.8927 - val_loss: 2.5297 - val_accuracy: 0.6751\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.6722 - accuracy: 0.8627 - val_loss: 2.3031 - val_accuracy: 0.5914\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 0.5459 - accuracy: 0.8944 - val_loss: 2.6197 - val_accuracy: 0.6599\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.5872 - accuracy: 0.8885 - val_loss: 2.7646 - val_accuracy: 0.6142\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5591 - accuracy: 0.8889 - val_loss: 6.0348 - val_accuracy: 0.5660\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5472 - accuracy: 0.8923 - val_loss: 2.0446 - val_accuracy: 0.6751\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5423 - accuracy: 0.8899 - val_loss: 4.0909 - val_accuracy: 0.6269\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5206 - accuracy: 0.9080 - val_loss: 3.9424 - val_accuracy: 0.6548\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.5683 - accuracy: 0.8990 - val_loss: 1.8060 - val_accuracy: 0.6142\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5395 - accuracy: 0.9017 - val_loss: 5.9908 - val_accuracy: 0.5228\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5603 - accuracy: 0.8986 - val_loss: 4.5160 - val_accuracy: 0.6269\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.5213 - accuracy: 0.9136 - val_loss: 1.7718 - val_accuracy: 0.6548\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.5257 - accuracy: 0.9122 - val_loss: 3.5553 - val_accuracy: 0.6548\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.5170 - accuracy: 0.9174 - val_loss: 3.1642 - val_accuracy: 0.6701\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4874 - accuracy: 0.9247 - val_loss: 10.0475 - val_accuracy: 0.4036\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.5120 - accuracy: 0.9171 - val_loss: 2.5905 - val_accuracy: 0.6904\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4785 - accuracy: 0.9230 - val_loss: 6.8168 - val_accuracy: 0.5076\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4785 - accuracy: 0.9216 - val_loss: 3.1634 - val_accuracy: 0.6777\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.5008 - accuracy: 0.9216 - val_loss: 4.5388 - val_accuracy: 0.6421\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4679 - accuracy: 0.9258 - val_loss: 2.1740 - val_accuracy: 0.6777\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.5011 - accuracy: 0.9185 - val_loss: 5.0106 - val_accuracy: 0.6523\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4497 - accuracy: 0.9376 - val_loss: 7.6669 - val_accuracy: 0.5508\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4570 - accuracy: 0.9296 - val_loss: 3.5192 - val_accuracy: 0.7056\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 0.4461 - accuracy: 0.9383 - val_loss: 6.4720 - val_accuracy: 0.6320\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4932 - accuracy: 0.9359 - val_loss: 2.4827 - val_accuracy: 0.7030\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4606 - accuracy: 0.9369 - val_loss: 3.7614 - val_accuracy: 0.6929\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4619 - accuracy: 0.9317 - val_loss: 9.8969 - val_accuracy: 0.5178\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4849 - accuracy: 0.9359 - val_loss: 3.3512 - val_accuracy: 0.7132\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4273 - accuracy: 0.9446 - val_loss: 3.2357 - val_accuracy: 0.7107\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 4s 42ms/step - loss: 0.4442 - accuracy: 0.9470 - val_loss: 13.3535 - val_accuracy: 0.3909\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4412 - accuracy: 0.9470 - val_loss: 3.9120 - val_accuracy: 0.7107\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.4372 - accuracy: 0.9467 - val_loss: 4.2674 - val_accuracy: 0.6574\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4251 - accuracy: 0.9502 - val_loss: 3.1042 - val_accuracy: 0.7259\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4526 - accuracy: 0.9470 - val_loss: 4.8041 - val_accuracy: 0.7005\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4238 - accuracy: 0.9537 - val_loss: 3.1887 - val_accuracy: 0.6599\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4343 - accuracy: 0.9495 - val_loss: 4.3309 - val_accuracy: 0.6548\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4102 - accuracy: 0.9544 - val_loss: 3.1806 - val_accuracy: 0.7386\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4450 - accuracy: 0.9488 - val_loss: 3.9637 - val_accuracy: 0.6929\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4566 - accuracy: 0.9460 - val_loss: 2.3563 - val_accuracy: 0.7360\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4226 - accuracy: 0.9554 - val_loss: 4.4294 - val_accuracy: 0.7360\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4062 - accuracy: 0.9568 - val_loss: 2.8309 - val_accuracy: 0.7563\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4349 - accuracy: 0.9547 - val_loss: 6.3806 - val_accuracy: 0.6371\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4702 - accuracy: 0.9369 - val_loss: 5.2171 - val_accuracy: 0.7030\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4451 - accuracy: 0.9456 - val_loss: 3.5538 - val_accuracy: 0.7538\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4254 - accuracy: 0.9575 - val_loss: 6.1591 - val_accuracy: 0.6878\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4230 - accuracy: 0.9530 - val_loss: 3.7932 - val_accuracy: 0.7437\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4172 - accuracy: 0.9596 - val_loss: 7.3232 - val_accuracy: 0.5914\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4013 - accuracy: 0.9645 - val_loss: 7.1761 - val_accuracy: 0.6675\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4069 - accuracy: 0.9589 - val_loss: 3.6251 - val_accuracy: 0.7310\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.4289 - accuracy: 0.9561 - val_loss: 4.8453 - val_accuracy: 0.7284\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4364 - accuracy: 0.9544 - val_loss: 6.7282 - val_accuracy: 0.6015\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 0.4196 - accuracy: 0.9655 - val_loss: 7.8842 - val_accuracy: 0.5533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e3ae582f98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels,\n",
    "         epochs=100,\n",
    "         validation_data=(test_images,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-expense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "latin-attack",
   "metadata": {},
   "source": [
    "### Tuning the base CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "hollywood-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    weight_decay = 1e-4\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay) ,input_shape=train_images.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    for i in range(5,hp.Int('Number_Of_Conv_Layers',min_value=6,max_value=12)):\n",
    "        model.add(Conv2D((2**i),(3,3), kernel_regularizer=regularizers.l2(weight_decay) , padding=hp.Choice('padding'+str(i),['valid','same'])))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        #model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(hp.Choice('Dropout'+str(i),[0.1,0.2,0.3,0.4,0.5])))\n",
    "        \n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=sgd,\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "needed-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory=os.path.normpath('C:/'),\n",
    "    project_name='Hyp_cnn_kaggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cutting-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "accurate-domain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 09m 49s]\n",
      "val_accuracy: 0.2664974530537923\n",
      "\n",
      "Best val_accuracy So Far: 0.2808798551559448\n",
      "Total elapsed time: 10h 48m 21s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_images, train_labels,epochs=100,validation_data=(test_images,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "worth-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 70, 70, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 70, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 70, 70, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 33, 33, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 33, 33, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 33, 33, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 33, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 31, 31, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 61504)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1968160   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,997,444\n",
      "Trainable params: 1,997,188\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-chest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-joshua",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-trustee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-galaxy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-sullivan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "focused-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(hp):\n",
    "    weight_decay = 1e-4\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay) ,input_shape=train_images.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    for i in range(5,hp.Int('Number_Of_Conv_Layers',min_value=6,max_value=12)):\n",
    "        model.add(Conv2D((2**i),(3,3), kernel_regularizer=regularizers.l2(weight_decay) , padding=hp.Choice('padding'+str(i),['valid','same'])))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(hp.Choice('Dropout'+str(i),[0.1,0.2,0.3,0.4,0.5])))\n",
    "        \n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=sgd,\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "realistic-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner2 = RandomSearch(\n",
    "    build_model2,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory=os.path.normpath('C:/'),\n",
    "    project_name='Hyp_cnn_kaggle2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cleared-forward",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 02m 37s]\n",
      "val_accuracy: 0.7335025668144226\n",
      "\n",
      "Best val_accuracy So Far: 0.7715736031532288\n",
      "Total elapsed time: 00h 05m 18s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "Number_Of_Conv_...|11                |8                 \n",
      "padding5          |same              |same              \n",
      "Dropout5          |0.5               |0.1               \n",
      "padding6          |same              |valid             \n",
      "Dropout6          |0.4               |0.1               \n",
      "padding7          |valid             |valid             \n",
      "Dropout7          |0.5               |0.1               \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1812, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-43-a871f64d5a58>\", line 14, in build_model2\n",
      "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 221, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 926, in __call__\n",
      "    input_list)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1117, in _functional_construction_call\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\", line 296, in call\n",
      "    data_format=conv_utils.convert_data_format(self.data_format, 4))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4520, in max_pool\n",
      "    name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 5269, in max_pool\n",
      "    data_format=data_format, name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 744, in _apply_op_helper\n",
      "    attrs=attr_protos, op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 593, in _create_op_internal\n",
      "    compute_device)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3485, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1975, in __init__\n",
      "    control_input_ops, op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1815, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1812, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-43-a871f64d5a58>\", line 14, in build_model2\n",
      "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 221, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 926, in __call__\n",
      "    input_list)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1117, in _functional_construction_call\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\", line 296, in call\n",
      "    data_format=conv_utils.convert_data_format(self.data_format, 4))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4520, in max_pool\n",
      "    name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 5269, in max_pool\n",
      "    data_format=data_format, name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 744, in _apply_op_helper\n",
      "    attrs=attr_protos, op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 593, in _create_op_internal\n",
      "    compute_device)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3485, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1975, in __init__\n",
      "    control_input_ops, op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1815, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1812, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-43-a871f64d5a58>\", line 14, in build_model2\n",
      "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 221, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 926, in __call__\n",
      "    input_list)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1117, in _functional_construction_call\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\", line 296, in call\n",
      "    data_format=conv_utils.convert_data_format(self.data_format, 4))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4520, in max_pool\n",
      "    name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 5269, in max_pool\n",
      "    data_format=data_format, name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 744, in _apply_op_helper\n",
      "    attrs=attr_protos, op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 593, in _create_op_internal\n",
      "    compute_device)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3485, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1975, in __init__\n",
      "    control_input_ops, op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1815, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1812, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-43-a871f64d5a58>\", line 14, in build_model2\n",
      "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 221, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 926, in __call__\n",
      "    input_list)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1117, in _functional_construction_call\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\", line 296, in call\n",
      "    data_format=conv_utils.convert_data_format(self.data_format, 4))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4520, in max_pool\n",
      "    name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 5269, in max_pool\n",
      "    data_format=data_format, name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 744, in _apply_op_helper\n",
      "    attrs=attr_protos, op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 593, in _create_op_internal\n",
      "    compute_device)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3485, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1975, in __init__\n",
      "    control_input_ops, op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1815, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1812, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-43-a871f64d5a58>\", line 14, in build_model2\n",
      "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 221, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 926, in __call__\n",
      "    input_list)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1117, in _functional_construction_call\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\", line 296, in call\n",
      "    data_format=conv_utils.convert_data_format(self.data_format, 4))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4520, in max_pool\n",
      "    name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 5269, in max_pool\n",
      "    data_format=data_format, name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 744, in _apply_op_helper\n",
      "    attrs=attr_protos, op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 593, in _create_op_internal\n",
      "    compute_device)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3485, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1975, in __init__\n",
      "    control_input_ops, op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1815, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 4/5\n",
      "Invalid model 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1812, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LightSpeed\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-43-a871f64d5a58>\", line 14, in build_model2\n",
      "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 221, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 926, in __call__\n",
      "    input_list)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1117, in _functional_construction_call\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\", line 296, in call\n",
      "    data_format=conv_utils.convert_data_format(self.data_format, 4))\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4520, in max_pool\n",
      "    name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 5269, in max_pool\n",
      "    data_format=data_format, name=name)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 744, in _apply_op_helper\n",
      "    attrs=attr_protos, op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 593, in _create_op_internal\n",
      "    compute_device)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3485, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1975, in __init__\n",
      "    control_input_ops, op_def)\n",
      "  File \"C:\\Users\\LightSpeed\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1815, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Too many failed attempts to build model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1811\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1812\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1813\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, hp)\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mmaybe_distribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-a871f64d5a58>\u001b[0m in \u001b[0;36mbuild_model2\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dropout'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    220\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 926\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m               \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         data_format=conv_utils.convert_data_format(self.data_format, 4))\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[0;32m   4519\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4520\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   4521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   5268\u001b[0m         \u001b[1;34m\"MaxPool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5269\u001b[1;33m                    data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   5270\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3484\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3485\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3486\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1974\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[1;32m-> 1975\u001b[1;33m                                 control_input_ops, op_def)\n\u001b[0m\u001b[0;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1814\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](batch_normalization_4/cond/Identity)' with input shapes: [?,1,1,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-73c04bf99553>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtuner2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'callbacks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36m_build_wrapper\u001b[1;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;31m# to the search space.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, hp)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_fail_streak\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                     raise RuntimeError(\n\u001b[1;32m--> 113\u001b[1;33m                         'Too many failed attempts to build model.')\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Too many failed attempts to build model."
     ]
    }
   ],
   "source": [
    "tuner2.search(train_images, train_labels,epochs=100,validation_data=(test_images,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-google",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "electric-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(hp):\n",
    "    try:\n",
    "        weight_decay = 1e-4\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay) ,input_shape=train_images.shape[1:]))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        for i in range(5,hp.Int('Number_Of_Conv_Layers',min_value=6,max_value=12)):\n",
    "            model.add(Conv2D((2**i),(3,3), kernel_regularizer=regularizers.l2(weight_decay) , padding=hp.Choice('padding'+str(i),['valid','same'])))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(Dropout(hp.Choice('Dropout'+str(i),[0.1,0.2,0.3,0.4,0.5])))\n",
    "\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(32,activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=sgd,\n",
    "                 loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "        return model\n",
    "    except:\n",
    "        weight_decay = 1e-4\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay) ,input_shape=train_images.shape[1:]))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        for i in range(5,hp.Int('Number_Of_Conv_Layers',min_value=6,max_value=12)):\n",
    "            model.add(Conv2D((2**i),(3,3), kernel_regularizer=regularizers.l2(weight_decay) , padding=hp.Choice('padding'+str(i),['valid','same'])))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            #model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(Dropout(hp.Choice('Dropout'+str(i),[0.1,0.2,0.3,0.4,0.5])))\n",
    "\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(32,activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=sgd,\n",
    "                 loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "mobile-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner3 = RandomSearch(\n",
    "    build_model3,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory=os.path.normpath('C:/'),\n",
    "    project_name='Hyp_cnn_kaggle3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adolescent-agent",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 35m 58s]\n",
      "val_accuracy: 0.25380709767341614\n",
      "\n",
      "Best val_accuracy So Far: 0.7715736031532288\n",
      "Total elapsed time: 02h 13m 38s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner3.search(train_images, train_labels,epochs=100,validation_data=(test_images,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "minimal-southeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 70, 70, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 70, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 70, 70, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 35, 35, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 35, 35, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 120,068\n",
      "Trainable params: 119,556\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner3.get_best_models(1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "muslim-evolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3654 - accuracy: 0.7716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3654427528381348, 0.7715736031532288]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "loaded-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "yprob_test = best_model.predict(test_images)\n",
    "ypred_test = [np.argmax(i) for i in yprob_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "involved-working",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22  41  30   7]\n",
      " [  1 113   1   0]\n",
      " [  0   0 105   0]\n",
      " [  0   4   6  64]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "conf_mx = confusion_matrix(test_labels, ypred_test)\n",
    "print(conf_mx)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "row_sums = conf_mx.sum(axis=1,keepdims=True)\n",
    "error_conf_mx = conf_mx/row_sums\n",
    "np.fill_diagonal(error_conf_mx,0)\n",
    "\n",
    "sns.heatmap(error_conf_mx, cmap=plt.cm.gray)\n",
    "plt.xlabel('Predicted',size=12)\n",
    "plt.ylabel('Actual',size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-congo",
   "metadata": {},
   "source": [
    "### We see that most of the miss classification can be attributed to :\n",
    "        Actual Class 0 -----> Model Predicting as Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aggregate-depression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.22      0.36       100\n",
      "           1       0.72      0.98      0.83       115\n",
      "           2       0.74      1.00      0.85       105\n",
      "           3       0.90      0.86      0.88        74\n",
      "\n",
      "    accuracy                           0.77       394\n",
      "   macro avg       0.83      0.77      0.73       394\n",
      "weighted avg       0.82      0.77      0.72       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, ypred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-robert",
   "metadata": {},
   "source": [
    "### Even from the Classification Report we can see that our model is doing a bad job at predicting Class 0 (f1=0.36) as compared to other Classes which the model is predicting pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "hundred-granny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-romantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-shopping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-grocery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-copying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-manhattan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
